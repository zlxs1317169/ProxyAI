project.label=ProxyAI
notification.group.name=notification.group.name
notification.group.sticky.name=notification.group.sticky.name
action.generateCommitMessage.title=生成提交消息
action.generateCommitMessage.description=生成git提交消息
action.generateCommitMessage.serviceWarning=消息只能通过OpenAI、自定义OpenAI或Azure服务生成
action.generateCommitMessage.missingCredentials=未提供凭据
action.includeFilesInContext.title=包含在上下文中...
action.includeFileInContext.title=包含文件在上下文中...
action.includeFilesInContext.dialog.title=包含在上下文中
action.includeFilesInContext.dialog.description=选择您希望包含在最终提示中的文件
action.includeFilesInContext.dialog.repeatableContext.label=可重复上下文：
action.includeFilesInContext.dialog.restoreToDefaults.label=恢复默认设置
action.openSettings.title=打开设置
action.openSettings.description=打开ProxyAI设置
action.statusbar.startServer.text=启动服务器
action.statusbar.startServer.description=启动LLaMA服务器
action.statusbar.startServer.MainMenu.text=启动服务器
action.statusbar.stopServer.text=停止服务器
action.statusbar.stopServer.description=停止LLaMA服务器
action.statusbar.stopServer.MainMenu.text=停止服务器
action.statusbar.enableCompletions.text=启用代码补全
action.statusbar.enableCompletions.description=启用代码补全功能
action.statusbar.enableCompletions.MainMenu.text=启用代码补全
action.statusbar.disableCompletions.text=禁用代码补全
action.statusbar.disableCompletions.description=禁用代码补全功能
action.statusbar.disableCompletions.MainMenu.text=禁用代码补全
action.statusbar.enableNextEdits.text=启用下一步编辑
action.statusbar.enableNextEdits.description=启用下一步编辑功能
action.statusbar.enableNextEdits.MainMenu.text=启用下一步编辑
action.statusbar.disableNextEdits.text=禁用下一步编辑
action.statusbar.disableNextEdits.description=禁用下一步编辑功能
action.statusbar.disableNextEdits.MainMenu.text=禁用下一步编辑
action.compareWithOriginal.title=与原始版本比较
action.applyDirectly.title=自动应用
action.explainGitCommit.title=使用ProxyAI解释提交
action.explainGitCommit.description=使用ProxyAI生成提交更改的详细说明
settings.displayName=ProxyAI: 设置
settings.openaiQuotaExceeded=OpenAI配额已超出。
settingsConfigurable.displayName.label=显示名称：
settingsConfigurable.service.label=选择的提供商：
settingsConfigurable.service.codeCompletion.label=代码补全提供商：
settingsConfigurable.service.codegpt.apiKey.comment=您可以在<a href="https://tryproxy.io/account">用户设置</a>中找到API密钥。
settingsConfigurable.service.codegpt.chatCompletionModel.comment=选择针对对话交互优化的模型，包括一般查询和解释的协助。
settingsConfigurable.service.codegpt.codeCompletionModel.comment=选择专为代码补全相关任务定制的模型。
settingsConfigurable.service.codegpt.enableNextEdits.comment=如果选中，ProxyAI将在您输入时建议多行更改。
settingsConfigurable.service.codegpt.enableCodeCompletion.comment=如果选中，ProxyAI将在您输入时建议更改。
settingsConfigurable.service.custom.openai.apiKey.comment=存储在系统钥匙串或KeePass中的秘密值，具体取决于您的操作系统。建议使用此方法，而不是将秘密作为纯文本存储在标头中。
settingsConfigurable.service.custom.openai.apiKey.provider.name=自定义提供商名称：
settingsConfigurable.service.custom.openai.exportDialog.filename=文件名：
settingsConfigurable.service.custom.openai.exportDialog.saveTo=保存到：
settingsConfigurable.service.custom.openai.exportDialog.title=目标文件
settingsConfigurable.service.custom.openai.exportDialog.exportError=导出OpenAI设置时出错
settingsConfigurable.service.custom.openai.exportDialog.importError=导入OpenAI设置时出错
settingsConfigurable.service.openai.apiKey.comment=您可以在<a href="https://platform.openai.com/account/api-keys">用户设置</a>中找到API密钥。
settingsConfigurable.service.openai.customModel.label=自定义模型：
settingsConfigurable.service.openai.organization.label=组织：
settingsConfigurable.section.openai.organization.comment=当您属于多个组织时很有用 <sup><strong>可选</strong></sup>
settingsConfigurable.service.google.apiKey.comment=您可以在<a href="https://aistudio.google.com/app/apikey">用户设置</a>中找到API密钥。
settingsConfigurable.service.google.model.comment=注意：Gemini Vision模型<a href="https://ai.google.dev/gemini-api/docs/get-started/web?multi-turn-conversations-chat&hl=en#multi-turn-conversations-chat">尚不支持聊天</a>。
settingsConfigurable.service.anthropic.apiKey.comment=您可以在<a href="https://console.anthropic.com/settings/keys">用户设置</a>中找到API密钥。
settingsConfigurable.service.anthropic.apiVersion.comment=我们始终建议尽可能使用<a href="https://docs.anthropic.com/claude/reference/versions">最新的API版本</a>。
settingsConfigurable.service.anthropic.model.comment=有关模型比较指标的详细信息，请参阅<a href="https://docs.anthropic.com/claude/docs/models-overview#model-comparison">模型比较</a>。
settingsConfigurable.service.llama.modelPreferences.title=模型首选项
settingsConfigurable.service.llama.serverPreferences.title=服务器首选项
settingsConfigurable.service.llama.modelSize.label=模型大小：
settingsConfigurable.service.llama.quantization.label=量化：
settingsConfigurable.service.llama.quantization.comment=量化是一种减少运行推理的计算和内存成本的技术。<a href="https://huggingface.co/docs/optimum/concept_guides/quantization">了解更多</a>
settingsConfigurable.service.llama.customModelPath.label=模型路径：
settingsConfigurable.service.llama.customModelPath.comment=仅支持.gguf文件
settingsConfigurable.service.llama.customServerPath.label=服务器路径：
settingsConfigurable.service.llama.customServerPath.comment=预编译的llama-cpp服务器可执行文件，仅支持.exe（Windows）或可执行文件（Linux）
settingsConfigurable.service.llama.promptTemplate.comment=选择在与语言模型交互时使用的模板。确保它与您正在使用的自定义模型匹配。
settingsConfigurable.service.llama.infillTemplate.comment=用于代码补全的模板。确保您正在使用的模型支持代码填充。
settingsConfigurable.service.llama.downloadModelLink.label=下载模型
settingsConfigurable.service.llama.cancelDownloadLink.label=取消下载
settingsConfigurable.service.llama.linkToModel.label=模型链接
settingsConfigurable.service.llama.contextSize.label=提示上下文大小：
settingsConfigurable.service.llama.contextSize.comment=提示上下文的大小。LLaMA模型是用2048的上下文构建的，这将为更长的输入/推理提供更好的结果。
settingsConfigurable.service.llama.threads.label=线程数：
settingsConfigurable.service.llama.threads.comment=可用于执行模型的线程数。不建议指定大于处理器核心数的数字。
settingsConfigurable.service.llama.additionalParameters.label=附加参数：
settingsConfigurable.service.llama.additionalParameters.comment=<html>服务器启动过程的附加命令行参数，用逗号分隔。查看完整的<a href="https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md">选项列表</a>。<p><i>示例："--n-gpu-layers, 1, --no-mmap, --mlock"</i></p></html>
settingsConfigurable.service.llama.additionalBuildParameters.label=附加构建参数：
settingsConfigurable.service.llama.additionalBuildParameters.comment=<html>服务器构建过程的附加命令行参数，用逗号分隔。查看完整的<a href="https://github.com/ggerganov/llama.cpp/tree/master?tab=readme-ov-file#build">构建选项列表</a>。<p><i>示例："LLAMA_CUDA=1,CUDA_DOCKER_ARCH=all"</i></p></html>
settingsConfigurable.service.llama.additionalEnvironmentVariables.label=附加环境变量：
settingsConfigurable.service.llama.additionalEnvironmentVariables.comment=<html>服务器构建和运行过程的附加环境变量，用空格分隔。可用于设置CUDA变量（查看完整的<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars">环境变量列表</a>）<p><i>示例："CUDA_VISIBLE_DEVICES=0,1"</i></p></html>
settingsConfigurable.service.llama.baseHost.label=基础主机：
settingsConfigurable.service.llama.baseHost.comment=现有LLama服务器的URL
settingsConfigurable.service.llama.startServer.label=启动服务器
settingsConfigurable.service.llama.startServer.opposite=停止
settingsConfigurable.service.llama.stopServer.label=停止服务器
settingsConfigurable.service.llama.stopServer.opposite=启动
settingsConfigurable.service.llama.progress.serverRunning=服务器运行中
settingsConfigurable.service.llama.progress.serverStopped=服务器已停止
settingsConfigurable.service.llama.progress.stoppingServer=正在停止服务器...
settingsConfigurable.service.llama.progress.startingServer=正在启动服务器...
settingsConfigurable.service.llama.progress.downloadingModel.title=正在下载模型
settingsConfigurable.service.llama.progress.downloadingModelIndicator.text=正在下载 %s...
settingsConfigurable.service.llama.overlay.modelNotDownloaded.text=模型未下载
settingsConfigurable.shared.authentication.title=身份验证
settingsConfigurable.shared.requestConfiguration.title=请求配置
settingsConfigurable.shared.apiKey.label=API密钥：
settingsConfigurable.shared.apiKey.comment=用于身份验证的API密钥，作为bearer添加到'Authorization'标头（可选）
settingsConfigurable.shared.baseHost.label=基础主机：
settingsConfigurable.shared.path.label=路径：
settingsConfigurable.shared.model.label=模型：
configurationConfigurable.displayName=ProxyAI: 配置
configurationConfigurable.table.title=编辑器操作
configurationConfigurable.table.emptyText=未配置操作
configurationConfigurable.table.header.actionColumnLabel=操作
configurationConfigurable.table.header.promptColumnLabel=提示
configurationConfigurable.table.action.revertToDefaults.text=恢复默认设置
configurationConfigurable.table.action.addKeymap.text=添加快捷键
configurationConfigurable.checkForPluginUpdates.label=自动检查插件更新
configurationConfigurable.checkForNewScreenshots.label=自动检查新截图
configurationConfigurable.openNewTabCheckBox.label=每次操作时打开新聊天
configurationConfigurable.enableMethodNameGeneration.label=启用方法名查找建议
configurationConfigurable.autoFormatting.label=启用自动代码格式化
configurationConfigurable.autocompletionPostProcessing.label=启用代码补全后处理
configurationConfigurable.autocompletionContextAwareCheckBox.label=启用项目上下文感知代码补全
configurationConfigurable.autocompletionGitContextCheckBox.label=为代码补全启用Git上下文
configurationConfigurable.section.assistant.title=助手配置
configurationConfigurable.section.assistant.systemPromptField.label=系统提示：
configurationConfigurable.section.assistant.systemPromptField.comment=系统消息有助于设置助手的行为
configurationConfigurable.section.assistant.temperatureField.label=温度：
configurationConfigurable.section.assistant.temperatureField.comment=随机性的值。必须在0和1之间
configurationConfigurable.section.assistant.maxTokensField.label=最大完成令牌：
configurationConfigurable.section.assistant.maxTokensField.comment=完成的最大容量。
configurationConfigurable.section.assistant.llamacppParams.title=llama.cpp的配置选项
configurationConfigurable.section.codeCompletion.title=代码补全
configurationConfigurable.section.codeCompletion.multiLineCompletions.description=如果选中，补全将能够跨越多行。
configurationConfigurable.section.codeCompletion.postProcess.title=启用tree-sitter后处理
configurationConfigurable.section.codeCompletion.postProcess.description=如果选中，补全将使用tree-sitter解析器进行后处理。
configurationConfigurable.section.codeCompletion.gitDiff.title=启用git diff上下文
configurationConfigurable.section.codeCompletion.collectDependencyStructure.title=启用依赖分析器
configurationConfigurable.section.codeCompletion.analyzeDepth.title=代码分析深度：
configurationConfigurable.section.codeCompletion.analyzeDepth.comment=该参数限制PSI结构遍历的深度。目前，它仅针对Kotlin语言实现。
configurationConfigurable.section.codeCompletion.collectDependencyStructure.description=启用该设置允许插件收集依赖结构，这提高了建议数据的准确性，但每个请求消耗更多令牌。目前，它仅针对Kotlin语言实现。
configurationConfigurable.section.codeCompletion.gitDiff.description=如果选中，在请求补全时将包含用户最近的未暂存git diff。
configurationConfigurable.section.chatCompletion.title=聊天补全
configurationConfigurable.section.chatCompletion.retryOnFailedDiffSearch.title=在diff搜索失败时启用重试
configurationConfigurable.section.chatCompletion.retryOnFailedDiffSearch.description=如果选中，插件将在diff搜索失败时重试。
configurationConfigurable.section.chatCompletion.editorContextTag.title=启用自动文件标记
configurationConfigurable.section.chatCompletion.editorContextTag.description=如果启用，来自打开的编辑器文件的内容将自动包含在您发送的每条消息中。
configurationConfigurable.section.chatCompletion.psiStructure.title=启用附加文件的依赖结构分析。
configurationConfigurable.section.chatCompletion.psiStructure.analyzeDepth.title=代码分析深度：
configurationConfigurable.section.chatCompletion.psiStructure.analyzeDepth.comment=该参数限制PSI结构遍历的深度。目前，它仅针对Kotlin语言实现。
configurationConfigurable.section.chatCompletion.psiStructure.description=如果启用，附加文件导入中存在的类结构将添加到对话的上下文中。结构是指文件中包含构造函数、字段和方法的源代码，包含所有修饰符、参数和返回类型，但没有实现。故意排除依赖项的实现，以便在高质量聊天上下文和节省令牌之间找到平衡。
settingsConfigurable.service.llama.predefinedModel.comment=从HuggingFace下载并使用经过审查的模型。
settingsConfigurable.service.llama.customModel.comment=使用您计算机本地路径中的自己的GGUF模型文件。
settingsConfigurable.service.custom.openai.testConnection.label=测试连接
settingsConfigurable.service.custom.openai.presetTemplate.label=预设模板：
settingsConfigurable.service.custom.openai.url.label=URL：
settingsConfigurable.service.custom.openai.linkToDocs=API文档链接
settingsConfigurable.service.custom.openai.connectionSuccess=连接成功。
settingsConfigurable.service.custom.openai.connectionFailed=连接失败。
settingsConfigurable.service.custom.openai.importSettings=导入设置...
settingsConfigurable.service.custom.openai.exportSettings=导出设置
settingsConfigurable.prompts.import=导入设置...
settingsConfigurable.prompts.export=导出设置
settingsConfigurable.prompts.exportDialog.saveTo=保存到：
settingsConfigurable.prompts.exportDialog.exportError=导出提示设置时出错
settingsConfigurable.prompts.exportDialog.title=目标文件
settingsConfigurable.prompts.importDialog.importError=导入提示设置时出错
settingsConfigurable.service.ollama.models.refresh=刷新模型
settingsConfigurable.service.ollama.codeCompletionModel.label=代码补全模型：
advancedSettingsConfigurable.displayName=ProxyAI: 高级设置
advancedSettingsConfigurable.proxy.title=HTTP/SOCKS代理
advancedSettingsConfigurable.proxy.typeComboBoxField.label=代理：
advancedSettingsConfigurable.proxy.hostField.label=主机名：
advancedSettingsConfigurable.proxy.authCheckBoxField.label=代理身份验证
advancedSettingsConfigurable.proxy.usernameField.label=用户名：
advancedSettingsConfigurable.proxy.passwordField.label=密码：
advancedSettingsConfigurable.connectionSettings.title=连接设置
advancedSettingsConfigurable.connectionSettings.connectionTimeout.label=连接超时（秒）：
advancedSettingsConfigurable.connectionSettings.readTimeout.label=读取超时（秒）：
codebaseIndexing.task.title=正在索引代码库
dialog.deleteConversation.title=删除对话
dialog.deleteConversation.description=您确定要删除此对话吗？
dialog.tokenLimitExceeded.title=令牌限制已超出
dialog.tokenLimitExceeded.description=已达到最大默认令牌限制。您是否要继续对话，尽管消息成本较高？
dialog.tokenSoftLimitExceeded.title=软限制已超出
dialog.tokenSoftLimitExceeded.description=警告：'git diff'输出包含%d个令牌，表明有大量更改。您确定要继续吗？
dialog.continue=继续
editor.diff.title=ProxyAI差异
editor.diff.local.content.title=ProxyAI建议的代码
toolwindow.chat.editor.action.copy.description=复制生成的代码
toolwindow.chat.editor.action.autoApply.title=自动应用
toolwindow.chat.editor.action.autoApply.disabledTitle=自动应用仅适用于ProxyAI提供商
toolwindow.chat.editor.action.autoApply.description=自动应用建议的更改
toolwindow.chat.editor.action.autoApply.noActiveFile=未找到活动文件
toolwindow.chat.editor.action.autoApply.fileTooLarge=活动文件太大无法处理
toolwindow.chat.editor.action.autoApply.reject=拒绝全部
toolwindow.chat.editor.diff.reading=正在读取...
toolwindow.chat.editor.diff.thinking=正在思考...
toolwindow.chat.editor.diff.editing=正在编辑...
toolwindow.chat.editor.diff.retrying=正在重试...
toolwindow.chat.editor.action.autoApply.error=应用更改时出现问题。{0}
toolwindow.chat.editor.action.autoApply.taskTitle=应用更改
toolwindow.chat.editor.action.autoApply.loadingMessage=ProxyAI: 正在应用更改
toolwindow.chat.editor.action.autoApply.successMessage=更改已成功应用到文件。
diff.acceptedPanel.revertChanges=撤销更改
diff.acceptedPanel.viewDetails=查看详情
diff.acceptedPanel.before=之前
diff.acceptedPanel.after=之后
toolwindow.chat.editor.action.diff.description=将编辑器代码与生成的代码进行差异比较
toolwindow.chat.editor.action.edit.title=编辑源码
toolwindow.chat.editor.action.disableEditing.title=禁用编辑
toolwindow.chat.editor.action.edit.description=编辑生成的代码
toolwindow.chat.editor.action.newFile.title=新建文件
toolwindow.chat.editor.action.newFile.description=从生成的代码创建新文件
toolwindow.chat.editor.action.replaceSelection.title=替换选择
toolwindow.chat.editor.action.replaceSelection.description=替换主编辑器选中的代码
toolwindow.chat.editor.action.insertAtCaret.title=在光标处插入
toolwindow.chat.editor.action.insertAtCaret.description=在主编辑器光标位置后插入生成的代码
toolwindow.chat.editor.action.expand=显示更多
toolwindow.chat.editor.action.collapse=显示更少
toolwindow.chat.response.action.reloadResponse.text=重新加载响应
toolwindow.chat.response.action.reloadResponse.description=重新加载响应描述
toolwindow.chat.response.action.deleteResponse.text=删除响应
toolwindow.chat.response.action.deleteResponse.description=删除响应描述
toolwindow.chat.youProCheckBox.text=使用GPT-4模型
toolwindow.chat.youProCheckBox.enable=为复杂查询开启
toolwindow.chat.youProCheckBox.disable=为更快响应关闭
toolwindow.chat.youProCheckBox.notAllowed=通过订阅YouPro计划启用
toolwindow.chat.textArea.emptyText=询问任何问题... 使用'@'包含额外上下文
action.generateCommitMessage.title=Generate Message
action.generateCommitMessage.description=Generate git commit message
action.generateCommitMessage.serviceWarning=Messages can only be generated with OpenAI, Custom OpenAI, or Azure service
action.generateCommitMessage.missingCredentials=Credentials not provided
action.includeFilesInContext.title=Include In Context...
action.includeFileInContext.title=Include File In Context...
action.includeFilesInContext.dialog.title=Include In Context
action.includeFilesInContext.dialog.description=Choose the files that you wish to include in the final prompt
action.includeFilesInContext.dialog.repeatableContext.label=Repeatable context:
action.includeFilesInContext.dialog.restoreToDefaults.label=Restore to Defaults
action.openSettings.title=Open Settings
action.openSettings.description=Open ProxyAI settings
action.statusbar.startServer.text=Start Server
action.statusbar.startServer.description=Start LLaMA Server
action.statusbar.startServer.MainMenu.text=Start Server
action.statusbar.stopServer.text=Stop Server
action.statusbar.stopServer.description=Stop LLaMA Server
action.statusbar.stopServer.MainMenu.text=Stop Server
action.statusbar.enableCompletions.text=Enable Autocomplete
action.statusbar.enableCompletions.description=Enable Autocomplete
action.statusbar.enableCompletions.MainMenu.text=Enable Autocomplete
action.statusbar.disableCompletions.text=Disable Autocomplete
action.statusbar.disableCompletions.description=Disable Autocomplete
action.statusbar.disableCompletions.MainMenu.text=Disable Autocomplete
action.statusbar.enableNextEdits.text=Enable Next Edits
action.statusbar.enableNextEdits.description=Enable Next Edits
action.statusbar.enableNextEdits.MainMenu.text=Enable Next Edits
action.statusbar.disableNextEdits.text=Disable Next Edits
action.statusbar.disableNextEdits.description=Disable Next Edits
action.statusbar.disableNextEdits.MainMenu.text=Disable Next Edits
action.compareWithOriginal.title=Compare with Original
action.applyDirectly.title=Auto Apply
action.explainGitCommit.title=Explain Commit with ProxyAI
action.explainGitCommit.description=Generate a detailed explanation of the commit changes using ProxyAI
settings.displayName=ProxyAI: Settings
settings.models.displayName=Models
settings.openaiQuotaExceeded=OpenAI quota exceeded.
settingsConfigurable.displayName.label=Display name:
settingsConfigurable.service.codegpt.apiKey.comment=You can find the API key in your <a href="https://tryproxy.io/account">User settings</a>.
settingsConfigurable.service.codegpt.chatCompletionModel.comment=Choose a model optimized for conversational interactions, including assistance with general queries and explanations.
settingsConfigurable.service.codegpt.codeCompletionModel.comment=Choose a model tailored for autocomplete-related tasks.
settingsConfigurable.service.codegpt.enableNextEdits.comment=If checked, ProxyAI will suggest multi-line changes as you type.
settingsConfigurable.service.codegpt.enableCodeCompletion.comment=If checked, ProxyAI will provide autocomplete suggestions as you type.
settingsConfigurable.service.custom.openai.apiKey.comment=A secret value stored in the system's Keychain or KeePass, depending on your OS. This approach is recommended over storing the secret in the header as plain text.
settingsConfigurable.service.custom.openai.apiKey.provider.name=Custom provider name:
settingsConfigurable.service.custom.openai.exportDialog.filename=File name:
settingsConfigurable.service.custom.openai.exportDialog.saveTo=Save to:
settingsConfigurable.service.custom.openai.exportDialog.title=Target File
settingsConfigurable.service.custom.openai.exportDialog.exportError=Error exporting OpenAI settings
settingsConfigurable.service.custom.openai.exportDialog.importError=Error importing OpenAI settings
settingsConfigurable.service.openai.apiKey.comment=You can find the API key in your <a href="https://platform.openai.com/account/api-keys">User settings</a>.
settingsConfigurable.service.openai.customModel.label=Custom model:
settingsConfigurable.service.openai.organization.label=Organization:
settingsConfigurable.section.openai.organization.comment=Useful when you are part of multiple organizations <sup><strong>optional</strong></sup>
settingsConfigurable.service.google.apiKey.comment=You can find the API key in your <a href="https://aistudio.google.com/app/apikey">User settings</a>.
settingsConfigurable.service.google.model.comment=Note: Gemini Vision models <a href="https://ai.google.dev/gemini-api/docs/get-started/web?multi-turn-conversations-chat&hl=en#multi-turn-conversations-chat">do not yet support chats</a>.
settingsConfigurable.service.anthropic.apiKey.comment=You can find the API key in your <a href="https://console.anthropic.com/settings/keys">User settings</a>.
settingsConfigurable.service.anthropic.apiVersion.comment=We always recommend using the <a href="https://docs.anthropic.com/claude/reference/versions">latest API version</a> whenever possible.
settingsConfigurable.service.anthropic.model.comment=For details on model comparison metrics, see <a href="https://docs.anthropic.com/claude/docs/models-overview#model-comparison">model comparison</a>.
settingsConfigurable.service.llama.modelPreferences.title=Model Preferences
settingsConfigurable.service.llama.serverPreferences.title=Server Preferences
settingsConfigurable.service.llama.modelSize.label=Model size:
settingsConfigurable.service.llama.quantization.label=Quantization:
settingsConfigurable.service.llama.quantization.comment=Quantization is a technique to reduce the computational and memory costs of running inference. <a href="https://huggingface.co/docs/optimum/concept_guides/quantization">Learn more</a>
settingsConfigurable.service.llama.customModelPath.label=Model path:
settingsConfigurable.service.llama.customModelPath.comment=Only .gguf files are supported
settingsConfigurable.service.llama.customServerPath.label=Server path:
settingsConfigurable.service.llama.customServerPath.comment=Precompiled executable llama-cpp server, only .exe (Windows) or executable File (Linux) are supported
settingsConfigurable.service.llama.promptTemplate.comment=Choose the template to use during interactions with the language model. Make sure it matches the custom model you're working with.
settingsConfigurable.service.llama.infillTemplate.comment=The template to use for autocomplete. Make sure the model you're working with supports code infilling.
settingsConfigurable.service.llama.downloadModelLink.label=Download Model
settingsConfigurable.service.llama.cancelDownloadLink.label=Cancel Downloading
settingsConfigurable.service.llama.linkToModel.label=Link to model
settingsConfigurable.service.llama.contextSize.label=Prompt context size:
settingsConfigurable.service.llama.contextSize.comment=The size of the prompt context. LLaMA models were built with a context of 2048, which will provide better results for longer input/inference.
settingsConfigurable.service.llama.threads.label=Threads:
settingsConfigurable.service.llama.threads.comment=The number of threads available to execute the model. It is not recommended to specify a number greater than the number of processor cores.
settingsConfigurable.service.llama.additionalParameters.label=Additional parameters:
settingsConfigurable.service.llama.additionalParameters.comment=<html>Additional command-line parameters for the server startup process, separated by commas. See the full <a href="https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md">list of options</a>.<p><i>Example: "--n-gpu-layers, 1,  --no-mmap, --mlock"</i></p></html>
settingsConfigurable.service.llama.additionalBuildParameters.label=Additional build parameters:
settingsConfigurable.service.llama.additionalBuildParameters.comment=<html>Additional command-line parameters for the server build process, separated by commas. See the full <a href="https://github.com/ggerganov/llama.cpp/tree/master?tab=readme-ov-file#build">list of build options</a>.<p><i>Example: "LLAMA_CUDA=1,CUDA_DOCKER_ARCH=all"</i></p></html>
settingsConfigurable.service.llama.additionalEnvironmentVariables.label=Additional environment variables:
settingsConfigurable.service.llama.additionalEnvironmentVariables.comment=<html>Additional environment variables for the server build and run process, separated by whitespaces. Can be used to e.g. set CUDA variables (see the full <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars">list of env vars</a>)<p><i>Example: "CUDA_VISIBLE_DEVICES=0,1"</i></p></html>
settingsConfigurable.service.llama.baseHost.label=Base host:
settingsConfigurable.service.llama.baseHost.comment=URL to existing LLama server
settingsConfigurable.service.llama.startServer.label=Start server
settingsConfigurable.service.llama.startServer.opposite=Stop
settingsConfigurable.service.llama.stopServer.label=Stop server
settingsConfigurable.service.llama.stopServer.opposite=Start
settingsConfigurable.service.llama.progress.serverRunning=Server running
settingsConfigurable.service.llama.progress.serverStopped=Server stopped
settingsConfigurable.service.llama.progress.stoppingServer=Stopping server...
settingsConfigurable.service.llama.progress.startingServer=Starting server...
settingsConfigurable.service.llama.progress.downloadingModel.title=Downloading Model
settingsConfigurable.service.llama.progress.downloadingModelIndicator.text=Downloading %s...
settingsConfigurable.service.llama.overlay.modelNotDownloaded.text=Model is not downloaded
settingsConfigurable.shared.authentication.title=Authentication
settingsConfigurable.shared.requestConfiguration.title=Request Configuration
settingsConfigurable.shared.apiKey.label=API key:
settingsConfigurable.shared.apiKey.comment=API Key for authentication, added to 'Authorization' header as bearer (Optional)
settingsConfigurable.shared.baseHost.label=Base host:
settingsConfigurable.shared.path.label=Path:
settingsConfigurable.shared.model.label=Model:
configurationConfigurable.displayName=ProxyAI: Configuration
configurationConfigurable.table.title=Editor Actions
configurationConfigurable.table.emptyText=No actions configured
configurationConfigurable.table.header.actionColumnLabel=Action
configurationConfigurable.table.header.promptColumnLabel=Prompt
configurationConfigurable.table.action.revertToDefaults.text=Revert to Defaults
configurationConfigurable.table.action.addKeymap.text=Add Shortcut
configurationConfigurable.checkForPluginUpdates.label=Check for plugin updates automatically
configurationConfigurable.checkForNewScreenshots.label=Check for new screenshots automatically
configurationConfigurable.openNewTabCheckBox.label=Open a new chat on each action
configurationConfigurable.enableMethodNameGeneration.label=Enable method name lookup suggestions
configurationConfigurable.autoFormatting.label=Enable automatic code formatting
configurationConfigurable.autocompletionPostProcessing.label=Enable code completion post processing
configurationConfigurable.autocompletionContextAwareCheckBox.label=Enable project context aware code completion
configurationConfigurable.autocompletionGitContextCheckBox.label=Enable Git context for code completions
configurationConfigurable.section.assistant.title=Assistant Configuration
configurationConfigurable.section.assistant.systemPromptField.label=System prompt:
configurationConfigurable.section.assistant.systemPromptField.comment=The system message helps to set the behaviour of the assistant
configurationConfigurable.section.assistant.temperatureField.label=Temperature:
configurationConfigurable.section.assistant.temperatureField.comment=The value of randomness. Must be between 0 and 1
configurationConfigurable.section.assistant.maxTokensField.label=Max completion tokens:
configurationConfigurable.section.assistant.maxTokensField.comment=The maximum capacity for completion.
configurationConfigurable.section.assistant.llamacppParams.title=Configuration Options for llama.cpp
configurationConfigurable.section.codeCompletion.title=Code Completion
configurationConfigurable.section.codeCompletion.multiLineCompletions.description=If checked, the completion will be able to span multiple lines.
configurationConfigurable.section.codeCompletion.postProcess.title=Enable tree-sitter post-processing
configurationConfigurable.section.codeCompletion.postProcess.description=If checked, the completion will be post-processed using the tree-sitter parser.
configurationConfigurable.section.codeCompletion.gitDiff.title=Enable git diff context
configurationConfigurable.section.codeCompletion.collectDependencyStructure.title=Enable dependency analyzer
configurationConfigurable.section.codeCompletion.analyzeDepth.title=Code analyze depth:
configurationConfigurable.section.codeCompletion.analyzeDepth.comment=The parameter limits the depth of the PSI structure traversal. Currently, it is implemented only for the Kotlin language.
configurationConfigurable.section.codeCompletion.collectDependencyStructure.description=Enabling the setting allows the plugin to collect the dependency structure, which increases the accuracy of the proposed data, but consumes more tokens per request. Currently, it is implemented only for the Kotlin language.
configurationConfigurable.section.codeCompletion.gitDiff.description=If checked, the user's most recent unstaged git diff will be included when requesting completion.
configurationConfigurable.section.chatCompletion.title=Chat Completion
configurationConfigurable.section.chatCompletion.retryOnFailedDiffSearch.title=Enable retry on failed diff search
configurationConfigurable.section.chatCompletion.retryOnFailedDiffSearch.description=If checked, the plugin will retry the diff search if it fails.
configurationConfigurable.section.chatCompletion.editorContextTag.title=Enable automatic file tagging
configurationConfigurable.section.chatCompletion.editorContextTag.description=If enabled, the content from open editor files will be automatically included with each message you send.
configurationConfigurable.section.chatCompletion.psiStructure.title=Enable dependency structure analysis of attached files.
configurationConfigurable.section.chatCompletion.psiStructure.analyzeDepth.title=Code analyze depth:
configurationConfigurable.section.chatCompletion.psiStructure.analyzeDepth.comment=The parameter limits the depth of the PSI structure traversal. Currently, it is implemented only for the Kotlin language.
configurationConfigurable.section.chatCompletion.psiStructure.description=If enabled, the class structure that is present in the imports of the attached files will be added in the context of the dialog. A structure refers to the source code in files that include constructors, fields, and methods, with all modifiers, arguments, and return types, but without an implementation. The implementation of dependencies is intentionally excluded in order to find a balance between a high-quality chat context and saving tokens.
settingsConfigurable.service.llama.predefinedModel.comment=Download and use vetted models from HuggingFace.
settingsConfigurable.service.llama.customModel.comment=Use your own GGUF model file from a local path on your computer.
settingsConfigurable.service.custom.openai.testConnection.label=Test Connection
settingsConfigurable.service.custom.openai.presetTemplate.label=Preset template:
settingsConfigurable.service.custom.openai.url.label=URL:
settingsConfigurable.service.custom.openai.linkToDocs=Link to API docs
settingsConfigurable.service.custom.openai.connectionSuccess=Connection successful.
settingsConfigurable.service.custom.openai.connectionFailed=Connection failed.
settingsConfigurable.service.custom.openai.importSettings=Import settings...
settingsConfigurable.service.custom.openai.exportSettings=Export settings
settingsConfigurable.prompts.import=Import settings...
settingsConfigurable.prompts.export=Export settings
settingsConfigurable.prompts.exportDialog.saveTo=Save to:
settingsConfigurable.prompts.exportDialog.exportError=Error exporting prompts settings
settingsConfigurable.prompts.exportDialog.title=Target File
settingsConfigurable.prompts.importDialog.importError=Error importing prompts settings
settingsConfigurable.service.ollama.models.refresh=Refresh Models
advancedSettingsConfigurable.displayName=ProxyAI: Advanced Settings
advancedSettingsConfigurable.proxy.title=HTTP/SOCKS Proxy
advancedSettingsConfigurable.proxy.typeComboBoxField.label=Proxy:
advancedSettingsConfigurable.proxy.hostField.label=Host name:
advancedSettingsConfigurable.proxy.authCheckBoxField.label=Proxy authentication
advancedSettingsConfigurable.proxy.usernameField.label=Username:
advancedSettingsConfigurable.proxy.passwordField.label=Password:
advancedSettingsConfigurable.connectionSettings.title=Connection Settings
advancedSettingsConfigurable.connectionSettings.connectionTimeout.label=Connection timeout (s):
advancedSettingsConfigurable.connectionSettings.readTimeout.label=Read timeout (s):
codebaseIndexing.task.title=Indexing codebase
dialog.deleteConversation.title=Delete Conversation
dialog.deleteConversation.description=Are you sure you want to delete this conversation?
dialog.tokenLimitExceeded.title=Token Limit Exceeded
dialog.tokenLimitExceeded.description=The maximum default token limit has been reached. Do you want to proceed with the conversation despite the higher messaging cost?
dialog.tokenSoftLimitExceeded.title=Soft Limit Exceeded
dialog.tokenSoftLimitExceeded.description=Warning: The 'git diff' output contains %d tokens, indicating a substantial amount of changes. Are you sure you want to continue?
dialog.continue=Continue
editor.diff.title=ProxyAI Diff
editor.diff.local.content.title=ProxyAI suggested code
toolwindow.chat.editor.action.copy.description=Copy generated code
toolwindow.chat.editor.action.autoApply.title=Auto Apply
toolwindow.chat.editor.action.autoApply.disabledTitle=Auto apply is only available with ProxyAI provider
toolwindow.chat.editor.action.autoApply.description=Apply suggested changes automatically
toolwindow.chat.editor.action.autoApply.noActiveFile=Active file not found
toolwindow.chat.editor.action.autoApply.fileTooLarge=Active file too large to process
toolwindow.chat.editor.action.autoApply.reject=Reject All
toolwindow.chat.editor.diff.applying=Applying
toolwindow.chat.editor.diff.thinking=Thinking
toolwindow.chat.editor.diff.editing=Editing
toolwindow.chat.editor.diff.retrying=Retrying
toolwindow.chat.editor.action.autoApply.error=Something went wrong while applying changes. {0}
toolwindow.chat.editor.action.autoApply.taskTitle=Apply changes
toolwindow.chat.editor.action.autoApply.loadingMessage=ProxyAI: Applying changes
toolwindow.chat.editor.action.autoApply.successMessage=Changes successfully applied to the file.
diff.acceptedPanel.revertChanges=Revert Changes
diff.acceptedPanel.viewDetails=View Details
diff.acceptedPanel.before=Before
diff.acceptedPanel.after=After
toolwindow.chat.editor.action.diff.description=Diff editor code against the generated one
toolwindow.chat.editor.action.edit.title=Edit Source
toolwindow.chat.editor.action.disableEditing.title=Disable Editing
toolwindow.chat.editor.action.edit.description=Edit generated code
toolwindow.chat.editor.action.newFile.title=New File
toolwindow.chat.editor.action.newFile.description=Create new file from generated code
toolwindow.chat.editor.action.replaceSelection.title=Replace Selection
toolwindow.chat.editor.action.replaceSelection.description=Replace main editor selected code
toolwindow.chat.editor.action.insertAtCaret.title=Insert at Caret
toolwindow.chat.editor.action.insertAtCaret.description=Insert generated code after main editor caret position
toolwindow.chat.editor.action.expand=Show More
toolwindow.chat.editor.action.collapse=Show Less
toolwindow.chat.response.action.reloadResponse.text=Reload Response
toolwindow.chat.response.action.reloadResponse.description=Reload response description
toolwindow.chat.response.action.deleteResponse.text=Delete Response
toolwindow.chat.response.action.deleteResponse.description=Delete response description
toolwindow.chat.youProCheckBox.text=Use GPT-4 model
toolwindow.chat.youProCheckBox.enable=Turn on for complex queries
toolwindow.chat.youProCheckBox.disable=Turn off for faster responses
toolwindow.chat.youProCheckBox.notAllowed=Enable by subscribing to YouPro plan
toolwindow.chat.textArea.emptyText=Ask anything... Use '@' to include additional context
service.codegpt.title=ProxyAI
service.openai.title=OpenAI
service.custom.openai.title=Custom OpenAI
service.anthropic.title=Anthropic
service.azure.title=Azure
service.google.title=Google
service.llama.title=LLaMA C/C++ (本地)
service.ollama.title=Ollama (本地)
validation.error.model.notExists='%s'不可用，请选择其他模型
validation.error.fieldRequired=此字段为必填项。
validation.error.invalidEmail=您输入的电子邮件无效。
validation.error.mustBeNumber=值必须是数字。
validation.error.mustBeBetweenZeroAndOne=值必须在0和1之间。
validation.error.mustBeGreaterThanZero=值必须大于0
checkForUpdatesTask.title=正在检查ProxyAI更新...
checkForUpdatesTask.notification.message=ProxyAI有可用更新。
checkForUpdatesTask.notification.installButton=安装更新
llamaServerAgent.buildingProject.description=正在构建服务器...
llamaServerAgent.serverBootup.description=正在启动服务器...
notification.compilationError.description=ProxyAI检测到编译错误。您是否需要帮助解决？
notification.compilationError.okLabel=解决错误
notification.completionError.description=补全失败：<br/>%s
statusBar.widget.tooltip=ProxyAI: 状态
shared.acceptAll=接受全部
shared.promptTemplate=提示模板：
shared.infillPromptTemplate=填充模板：
shared.apiVersion=API版本：
shared.escToCancel=按Esc取消
shared.cancel=取消
shared.confirm=确认
shared.copy=复制
shared.copyCode=复制代码
shared.copyMessageContents=复制消息内容
shared.copyToClipboard=复制到剪贴板
shared.copiedToClipboard=已复制到剪贴板
shared.configuration=配置
shared.delete=删除消息
shared.deleteDescription=删除消息
shared.reload=重新加载消息
shared.reloadDescription=重新加载消息
shared.port=端口：
shared.discard=丢弃
shared.notification.doNotShowAgain=不再显示
shared.loading=正在加载...
shared.website=网站
codeCompletion.progress.title=代码补全进行中
imageAttachmentNotification.content=检测到桌面上的新图像。您是否要将其附加到当前对话？
imageAttachmentNotification.action=附加图像
action.attachImage=附加图像
action.attachImageDescription=附加图像
imageFileChooser.title=选择图像
imageAccordion.title=附加的图像
shared.image=图像
shared.chatCompletions=聊天补全
shared.codeCompletions=代码补全
codeCompletionsForm.enableFeatureText=启用代码补全
codeCompletionsForm.parseResponseAsChatCompletions=将响应解析为聊天补全
codeCompletionsForm.overrideFimTemplate.label=使用内置FIM模板
codeCompletionsForm.overrideFimTemplate.description=如果选中，ProxyAI将为选定的模型应用相应的FIM模板。
codeCompletionsForm.selectFimTemplate=FIM模板：
codeCompletionsForm.maxTokensLabel=最大令牌：
codeCompletionsForm.maxTokensComment=代码补全中将生成的最大令牌数。
editCodePopover.title=编辑代码
editCodePopover.textField.emptyText=编辑说明...
editCodePopover.textField.followUp.emptyText=提出后续问题
editCodePopover.textField.comment=为代码修改提供说明。
editCodePopover.submitButton.title=提交编辑
editCodePopover.acceptButton.title=接受建议
editCodePopover.followUpButton.title=提交后续问题
smartTextPane.submitButton.title=发送消息
smartTextPane.submitButton.description=发送消息
smartTextPane.stopButton.title=停止
smartTextPane.stopButton.description=停止补全
chatMessageResponseBody.webPages.title=网页
chatMessageResponseBody.webDocs.startProgress.label=正在分析网页内容...
addDocumentation.popup.title=添加文档
addDocumentation.popup.form.name.label=名称：
addDocumentation.popup.form.url.label=URL：
addDocumentation.popup.form.url.comment=输入文档的完整网址。
addDocumentation.popup.form.saveCheckbox.label=保存以供将来参考
userMessagePanel.documentation.title=文档
userMessagePanel.persona.title=角色
suggestionGroupItem.files.displayName=文件
suggestionGroupItem.folders.displayName=文件夹
suggestionGroupItem.personas.displayName=角色
suggestionGroupItem.history.displayName=历史
suggestionGroupItem.docs.displayName=文档
service.mistral.title=Mistral
service.llama.title=LLaMA C/C++
service.ollama.title=Ollama
validation.error.model.notExists='%s' is not available, please select another model
validation.error.fieldRequired=This field is required.
validation.error.invalidEmail=The email you entered is invalid.
validation.error.mustBeNumber=Value must be number.
validation.error.mustBeBetweenZeroAndOne=Value must be between 0 and 1.
validation.error.mustBeGreaterThanZero=Value must be greater than 0
checkForUpdatesTask.title=Checking for ProxyAI update...
checkForUpdatesTask.notification.message=An update for ProxyAI is available.
checkForUpdatesTask.notification.installButton=Install update
llamaServerAgent.buildingProject.description=Building server...
llamaServerAgent.serverBootup.description=Booting up server...
notification.compilationError.description=ProxyAI has detected a compilation error. Would you like assistance in resolving it?
notification.compilationError.okLabel=Resolve errors
notification.completionError.description=Completion failed:<br/>%s
statusBar.widget.tooltip=ProxyAI: Status
shared.acceptAll=Accept All
shared.promptTemplate=Prompt template:
shared.infillPromptTemplate=Infill template:
shared.apiVersion=API version:
shared.escToCancel=Esc to cancel
shared.cancel=Cancel
shared.confirm=Confirm
shared.copy=Copy
shared.copyCode=Copy Code
shared.copyMessageContents=Copy Message Contents
shared.copyToClipboard=Copy to clipboard
shared.copiedToClipboard=Copied to clipboard
shared.configuration=Configuration
shared.delete=Delete Message
shared.deleteDescription=Delete message
shared.reload=Reload Message
shared.reloadDescription=Reload message
shared.port=Port:
shared.discard=Discard
shared.notification.doNotShowAgain=Do not show again
shared.loading=Loading...
shared.website=Website
codeCompletion.progress.title=Code completion in progress
imageAttachmentNotification.content=New image detected on desktop. Would you like to attach it to your current conversation?
imageAttachmentNotification.action=Attach image
action.attachImage=Attach Image
action.attachImageDescription=Attach an image
imageFileChooser.title=Select Image
imageAccordion.title=Attached image
shared.image=Image
shared.chatCompletions=Chat Completions
shared.codeCompletions=Code Completions
codeCompletionsForm.enableFeatureText=Enable code completions
codeCompletionsForm.parseResponseAsChatCompletions=Parse response as Chat Completions
codeCompletionsForm.overrideFimTemplate.label=Use built-in FIM template
codeCompletionsForm.overrideFimTemplate.description=If checked, ProxyAI will apply the corresponding FIM template for the selected model.
codeCompletionsForm.selectFimTemplate=FIM template:
codeCompletionsForm.maxTokensLabel=Max tokens:
codeCompletionsForm.maxTokensComment=The maximum number of tokens that will be generated in the code completion.
editCodePopover.title=Edit Code
editCodePopover.textField.emptyText=Editing instructions...
editCodePopover.textField.followUp.emptyText=Ask a follow-up question
editCodePopover.textField.comment=Provide instructions for the code modification.
editCodePopover.submitButton.title=Submit Edit
editCodePopover.acceptButton.title=Accept Suggestion
editCodePopover.followUpButton.title=Submit Follow-up
smartTextPane.submitButton.title=Send Message
smartTextPane.submitButton.description=Send message
smartTextPane.stopButton.title=Stop
smartTextPane.stopButton.description=Stop completion
chatMessageResponseBody.webPages.title=WEB PAGES
chatMessageResponseBody.webDocs.startProgress.label=Analyzing web content...
addDocumentation.popup.title=Add Documentation
addDocumentation.popup.form.name.label=Name:
addDocumentation.popup.form.url.label=URL:
addDocumentation.popup.form.url.comment=Enter the full web address of the documentation.
addDocumentation.popup.form.saveCheckbox.label=Save for future reference
userMessagePanel.documentation.title=DOCUMENTATION
userMessagePanel.persona.title=PERSONA
suggestionGroupItem.files.displayName=Files
suggestionGroupItem.folders.displayName=Folders
suggestionGroupItem.personas.displayName=Personas
suggestionGroupItem.history.displayName=History
suggestionGroupItem.docs.displayName=Docs
suggestionGroupItem.git.displayName=Git
suggestionGroupItem.mcp.displayName=MCP (即将推出)
suggestionGroupItem.codeAnalyze.displayName=代码分析
suggestionActionItem.attachImage.displayName=图像
suggestionActionItem.attachImage.description=选择要附加的图像文件
suggestionActionItem.webSearch.displayName=网页
suggestionActionItem.viewDocumentations.displayName=查看所有文档
suggestionActionItem.createPersona.displayName=添加新角色
suggestionActionItem.createDocumentation.displayName=添加新文档
suggestionActionItem.includeOpenFiles.displayName=包含打开的文件
suggestionActionItem.includeCurrentChanges.displayName=包含当前更改
tagPopupMenuItem.close=关闭
tagPopupMenuItem.closeOthers=关闭其他标签
tagPopupMenuItem.closeAll=关闭所有标签
tagPopupMenuItem.closeTagsToLeft=关闭左侧标签
tagPopupMenuItem.closeTagsToRight=关闭右侧标签
toolwindow.chat.loading=正在生成响应...
headerPanel.error.searchBlockNotMapped.title=无法定位搜索块
llama.build.cmake.setup=正在设置CMake...
llama.build.cmake.build=正在构建项目...
llama.build.startingBuild=开始构建Llama服务器
llama.build.phase.setup=阶段1：CMake设置
llama.build.phase.build=阶段2：构建项目
llama.build.phase.setupFailed=CMake设置失败
llama.build.phase.buildFailed=构建失败
llama.build.cache.cleanup=检测到CMake缓存路径不匹配，正在清理构建目录...
llama.server.buildStopped=用户停止构建
llama.server.starting=正在启动服务器...
llama.server.running=服务器运行成功
llama.server.startupFailed=服务器启动失败
llama.server.stopping.cmake=正在停止CMake设置过程
llama.server.stopping.build=正在停止构建过程
llama.error.server.startup=无法启动llama服务器：\n{0}
llama.error.server.startupWithDetails=服务器启动失败：{0}
llama.ui.tab.serverConfiguration=服务器配置
llama.ui.tab.serverLogs=服务器日志
llama.ui.tab.buildOutput=构建输出
llama.ui.button.stopBuild=停止构建
llama.ui.status.running=服务器状态：运行中
llama.ui.status.building=服务器状态：构建中...
llama.ui.status.stopped=服务器状态：已停止
llama.ui.status.prefix=服务器状态：{0}
llama.ui.action.clear=清除
llama.ui.action.clear.description=清除控制台
llama.ui.action.scrollToEnd=滚动到底部
llama.ui.action.scrollToEnd.description=滚动到底部
llama.process.startingBuild=正在启动服务器构建过程...
llama.debug.buildLoggingStrategy=调试：构建日志策略已初始化
suggestionGroupItem.mcp.displayName=MCP (soon)
suggestionGroupItem.codeAnalyze.displayName=Code Analyze
suggestionActionItem.attachImage.displayName=Image
suggestionActionItem.attachImage.description=Select an image file to attach
suggestionActionItem.webSearch.displayName=Web
suggestionActionItem.viewDocumentations.displayName=View all docs
suggestionActionItem.createPersona.displayName=Add new persona
suggestionActionItem.createDocumentation.displayName=Add new doc
suggestionActionItem.includeOpenFiles.displayName=Include Open Files
suggestionActionItem.includeCurrentChanges.displayName=Include Current Changes
tagPopupMenuItem.close=Close
tagPopupMenuItem.closeOthers=Close Other Tags
tagPopupMenuItem.closeAll=Close All Tags
tagPopupMenuItem.closeTagsToLeft=Close Tags to the Left
tagPopupMenuItem.closeTagsToRight=Close Tags to the Right
toolwindow.chat.loading=Generating response...
headerPanel.error.searchBlockNotMapped.title=Failed to Locate Search Block
llama.build.cmake.setup=Setting up CMake...
llama.build.cmake.build=Building project...
llama.build.startingBuild=Starting Llama Server Build
llama.build.phase.setup=Phase 1: CMake Setup
llama.build.phase.build=Phase 2: Building Project
llama.build.phase.setupFailed=CMake setup failed
llama.build.phase.buildFailed=Build failed
llama.build.cache.cleanup=Detected CMake cache path mismatch, cleaning up build directory...
llama.server.buildStopped=Build stopped by user
llama.server.starting=Starting server...
llama.server.running=Server running successfully
llama.server.startupFailed=Server startup failed
llama.server.stopping.cmake=Stopping CMake setup process
llama.server.stopping.build=Stopping build process
llama.error.server.startup=Unable to start llama server:\n{0}
llama.error.server.startupWithDetails=Server startup failed: {0}
llama.ui.tab.serverConfiguration=Server Configuration
llama.ui.tab.serverLogs=Server Logs
llama.ui.tab.buildOutput=Build Output
llama.ui.button.stopBuild=Stop Build
llama.ui.status.running=Server status: Running
llama.ui.status.building=Server status: Building...
llama.ui.status.stopped=Server status: Stopped
llama.ui.action.clear=Clear
llama.ui.action.clear.description=Clear console
llama.ui.action.scrollToEnd=Scroll to End
llama.ui.action.scrollToEnd.description=Scroll to bottom
llama.process.startingBuild=Starting server build process...
llama.debug.buildLoggingStrategy=DEBUG: Build logging strategy initialized
settings.models.chat.label=Chat:
settings.models.code.label=Autocomplete:
settings.models.autoApply.label=Auto apply:
settings.models.commitMessages.label=Commit messages:
settings.models.editCode.label=Edit code:
settings.models.nextEdit.label=Next edits:
settings.models.nameLookups.label=Name lookups:
settings.models.selectModel=Select a model
settings.models.chat.section.title=Chat
settings.models.chat.section.description=Models for conversations, code edits, auto applies, commits, and naming suggestions. <a href="https://docs.tryproxy.io/editor/chat/overview">Learn more</a>
settings.models.tab.section.title=Tab
settings.models.tab.section.description=Models for autocomplete and multi-line next edit suggestions. <a href="https://docs.tryproxy.io/editor/tab">Learn more</a>
conversation.deleteButton.tooltip=Delete conversation
conversation.messageCount.singular={0} message
conversation.messageCount.plural={0} messages
conversation.defaultTitle=New Conversation
conversation.emptyState=Your conversations will be saved here for easy access.
conversation.searchField.placeholder=Search in titles and messages...
conversation.searchResult.singular={0} match found
conversation.searchResult.plural={0} matches found
conversation.sortOption.recentlyUpdated=Recently Updated
conversation.sortOption.oldestFirst=Oldest First
conversation.sortOption.titleAscending=Title (A-Z)
conversation.sortOption.titleDescending=Title (Z-A)
conversation.sortOption.mostMessages=Most Messages
conversation.sortOption.leastMessages=Least Messages
conversation.sortAction.title=Sort: {0}
conversation.sortAction.description=Sort conversations by {0}
conversation.sortPopup.title=Sort By
conversation.refreshAction.title=Refresh
conversation.refreshAction.description=Refresh conversation list
conversation.status.searchResult=Found {0} of {1} conversations
conversation.status.count.singular={0} conversation
conversation.status.count.plural={0} conversations
conversation.status.sortedBy=Sorted by: {0}
conversation.deleteConfirmation.message=Are you sure you want to delete this conversation?
conversation.deleteConfirmation.title=Delete Conversation
